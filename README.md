# The Impostor Hunt in Text: Detecting AI-Generated Text

[![Python Version](https://img.shields.io/badge/python-3.9-blue.svg)](https://www.python.org/downloads/release/python-390/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This project is a data science portfolio piece that tackles the "The Impostor Hunt in Text" Kaggle competition. The goal is to distinguish between human-written and AI-generated text.

## ðŸŽ¯ Motivation

In an era where AI can generate text that is nearly indistinguishable from human writing, the ability to detect AI-generated content is becoming increasingly crucial. This capability is vital for:

*   **Maintaining Authenticity and Credibility:** Distinguishing between human and machine-generated text helps readers assess the trustworthiness of the content they consume.
*   **Upholding Academic Integrity:** In educational settings, AI detection tools are essential for identifying plagiarism and ensuring that students are submitting their own original work.
*   **Preventing the Spread of Misinformation:** AI can be used to generate large volumes of fake news and propaganda. Detecting AI-generated text is a critical step in curbing the spread of such misinformation.

This project aims to develop a robust machine learning model that can accurately identify AI-generated text, contributing to the efforts to ensure a more transparent and trustworthy digital environment.

## ðŸ“– Project Overview

The project implements a machine learning pipeline to classify text as either human-written or AI-generated. It uses a variety of linguistic and semantic features to train a set of models, which are then combined into an ensemble for improved accuracy.

### The Dataset

The dataset consists of pairs of text, where one is written by a human and the other is generated by an AI. The task is to identify the AI-generated text. The data is structured as follows:

-   `train.csv`: Contains the training data, with the `id` of the text pair and the `real_text_id` (1 or 2) indicating which text is human-written.
-   `train/`: A directory containing subdirectories for each text pair, with each subdirectory containing two files: `file_1.txt` and `file_2.txt`.
-   `test/`: A directory with the same structure as `train/`, but without the corresponding `train.csv` file.

### The Approach

The project uses a feature-based approach to solve the problem. The following steps are taken:

1.  **Data Loading and Preprocessing:** The text data is loaded from the file system and preprocessed to extract relevant features.
2.  **Feature Engineering:** A wide range of features are extracted from the text, including:
    *   **Linguistic Features:** Basic statistics (length, word count, sentence count), readability scores (Flesch reading ease, Flesch-Kincaid grade), sentiment scores, punctuation counts, and more.
    *   **Semantic Features:** TF-IDF similarity, word overlap, and length differences between the two texts in a pair.
3.  **Model Training:** Several machine learning models are trained on the extracted features, including:
    *   Random Forest
    *   XGBoost
    *   LightGBM
    *   Logistic Regression
4.  **Ensemble Modeling:** The trained models are combined into a `VotingClassifier` ensemble to make the final prediction.
5.  **Prediction:** The trained ensemble model is used to predict which text in the test set is AI-generated.

## ðŸš€ Getting Started

To run the project, you will need to have Python 3 and the required libraries installed.

### Prerequisites

-   Python 3
-   The libraries listed in the `requirements.txt` file.

### Installation

1.  Clone the repository:
    ```bash
    git clone https://github.com/dobercode/The-Impostor-Hunt-in-Text.git
    ```
2.  Install the required libraries:
    ```bash
    pip install -r requirements.txt
    ```

### Usage

To run the full pipeline, including data loading, feature engineering, model training, and prediction, run the `main.py` script:

```bash
python main.py
```

This will generate a `submission.csv` file in the root directory, which can be submitted to the Kaggle competition.

### Web Application

This project includes an interactive web application built with Streamlit. To run the app, use the following command:

```bash
streamlit run app.py
```

This will start a local web server and open the application in your browser.

### Testing

Unit tests are included to ensure the reliability of the code. To run the tests, use the following command:

```bash
pytest
```

## ðŸ“‚ Project Structure

The project is structured as follows:

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ main.py
â”œâ”€â”€ notebooks
â”‚   â””â”€â”€ the-impostor-hunt-in-texts.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ test_analyzer.py
â”‚   â””â”€â”€ test_classifier.py
â””â”€â”€ src
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ analyzer.py
    â””â”€â”€ classifier.py
```

-   `app.py`: The Streamlit web application.
-   `main.py`: The main script to run the pipeline.
-   `notebooks/`: Contains the Jupyter notebook with a more detailed analysis and advanced models.
-   `README.md`: This file.
-   `requirements.txt`: The required libraries to run the project.
-   `pytest.ini`: Configuration file for pytest.
-   `tests/`: Contains the unit tests for the project.
-   `src/`: The source code for the project.
    -   `analyzer.py`: Contains the `TextAuthenticityAnalyzer` class for feature extraction.
    -   `classifier.py`: Contains the `TextAuthenticityClassifier` class for model training and prediction.

## ðŸ“ˆ Results

The ensemble model achieves a validation accuracy of **84.21%**. The feature importance analysis shows that the most important features are related to text length, readability, and sentiment.

### Model Performance

| Model                  | Cross-Validation Accuracy | Validation Accuracy |
| ---------------------- | ------------------------- | ------------------- |
| Random Forest          | 0.8417                    | 0.7895              |
| XGBoost                | 0.8550                    | 0.8421              |
| LightGBM               | 0.8408                    | 0.8421              |
| Logistic Regression    | 0.8150                    | 0.8421              |
| **Ensemble**           | -                         | **0.8421**          |

### Visualizations

The notebook contains a variety of visualizations to explore the data and the model's performance. These include:

*   **Feature Distributions:** Plots showing the distribution of different linguistic features for real and fake text.
*   **Feature Importance:** A plot showing the most important features for the model.
*   **Confusion Matrix:** A confusion matrix to visualize the model's performance.

Here is the feature importance plot:

<p align="center">
  <img src="https://i.imgur.com/YOUR_IMAGE_URL.png" alt="Feature Importance">
</p>

## í“¨ Future Work

-   **Advanced Feature Engineering:** Explore more advanced features, such as those based on transformer models (e.g., BERT, RoBERTa).
-   **Hyperparameter Tuning:** Perform more extensive hyperparameter tuning to optimize the models.
-   **Data Augmentation:** Use data augmentation techniques to increase the size of the training set and improve model generalization.

## ðŸ“„ License

This project is licensed under the MIT License. See the `LICENSE` file for details.